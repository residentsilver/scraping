# Green Japan スクレイピングツール

このツールは、Green Japanのお気に入りページから求人情報を取得し、Excelファイルとして保存するPythonスクリプトです。

## 機能

- Green Japanへのログイン処理
- お気に入り登録した求人情報のスクレイピング
- 詳細ページからの追加情報取得
- Excelファイルへのデータ出力

## 取得データ

主に以下の情報を取得します：

- 企業名
- 給与
- 勤務地
- 勤務時間
- 働き方
- 平均年齢
- みなし残業時間
- 平均残業時間
- 休日日数
- 実務経験要件
- 利用言語
- 掲載ページURL
- 社員数
- 設立年数
- その他カスタム項目（手動で入力するフィールド）

## 必要環境

- Python 3.6以上
- Chrome ブラウザ

## 必要ライブラリ

```
selenium
pandas
webdriver-manager
openpyxl
```

## インストール方法

1. リポジトリをクローンするか、ファイルをダウンロード
2. 必要なライブラリをインストール

```bash
pip install -r requirements.txt
```

## 使い方

### 1. 設定ファイルの編集（オプション）

`config.py` ファイルを編集して、ログイン情報などを設定できます：

```python
EMAIL = "your.email@example.com"  # Green Japanのログインメールアドレス
PASSWORD = "your_password"  # Green Japanのログインパスワード
```

### 2. スクリプトの実行

```bash
python green_scraper.py
```

設定ファイルにログイン情報を入力していない場合は、実行時にコマンドラインで入力を求められます。

### 3. 出力データの確認

スクレイピングされたデータは、`output_YYYYMMDD` ディレクトリ内の Excel ファイルに保存されます。

## 注意事項

- Green Japanの利用規約に従って使用してください
- 過度なアクセスはサーバーに負荷をかけるため、適切な間隔を空けて実行してください
- ログイン情報を保存する場合は、`config.py` が第三者に漏れないよう注意してください

## エラー対応

エラーが発生した場合は、`scraping.log` ファイルを確認して問題を特定してください。

## カスタマイズ

サイトの構造が変更された場合は、セレクタやHTML要素の識別子を更新する必要があります。
主に `GreenScraper` クラスの `scrape_favorites` メソッドと `get_detailed_info` メソッドを確認してください。 